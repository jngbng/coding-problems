폐장 시점에 최대 1,000개 클라이언트
데이터는 이미 주어져 있다.

개발/배포,모니터링,전송되는 정보를 관리.
기술 스택, 방법은 마음대로 선택 가능.

최대 1,000개라는게 동시에 1,000개라는건가?

일단 정보를 보내는데 방식은 풀과 푸쉬 방식이 있는데, 풀이 좀더 안정적이고 구현 복잡도가 낮다.

그래서 가장 일단 심플하게 생각해보면서 문제들을 파악해 나가겠다.

가장 요즘 흔하게 쓰는 방식으로 REST API 방식으로 생각해보자.

클라 <--->  서버 <--- DB

를 생각해볼 수 있다.

1. 클라이언트가 시장 폐장 시점에 API 요청을 하고, 서버는 폐장이 되었고 데이터가 있으면 보내준다.

여기서 발생하는 문제는, 클라이언트와 서버의 시간 동기화가 문제가 된다. 클라이언트는 언제 쏴야 하는 지 어떻게 아나?

일단 이 문제는 동기화 되어 있다고 생각하자. (별도의 문제로 클라이언트가 clock synchronize 방식을 써서 시간은 application 레벨에서 서버와 동기화 한다고 하자.)

2. 요청할 때는 어느 날의 종점 데이터를 요청하는 지를 인자로 보내야 할 것 같다.

그럼 데이터를 보낼껀데, 이걸 전체를 보낼껀지, 특정 종목을 보낼껀지를 정해야 한다.
여기서 유저들의 행동이 어떤지 생각해봐야 하는데, 일반적으로 주식앱에서 사용자는 자기가 관심있는 여러 종목정보들을 빠르게 보길 원하기 때문에, 여러 정목들을 받길 원할꺼다.

그래서 전체 정보를 다 보내는게 얼마나 큰지를 생각해야 한다. 가장 작은 데이터는 (종목, 종가, 시가, 최고, 최저)니깐 8byte, 가격은 각각을 16bytes로 넉넉히 잡으면, 68 byte 정도이다. 종목은 장에 따라 다른데 10만개 정도로 잡으면 680만 byte = 7MB 정도이다. 이 정도면 전송에 시간이 오래 걸리기 때문에 전체를 보내는건 부담스럽긴 하다.

그래서 전체 목록은 1000개 (68KB) 정도로 끊어서 받도록 하고,
관심 목록을 인자로 받아서 해당 정보만 내려주는 API를 하나 더 만들면 좋겠다.

3. 그러면 종점이 되었을 때 서버에 요청이 일시적으로 몰릴꺼고, 서버는 빠르게 처리할 수 있어야 한다.

부하는 클라들 -> 서버 쪽 부하. 서버 -> DB 부하가 있는데.

서버 -> DB 부하.

3-1. 일단 한 노드 기준으로 생각해보면 종점 시점 기준으로 데이터는 더 이상 변하지 않기 때문에 DB에서 읽어와서 in-memory로 캐시해서 서버 -> DB 부하를 줄일 수 있깄다. 그리고 한 서버 시점 기준에서 같이 들어온 데이터는 같은 데이터로 응답하면 되기 때문에 전체 프로세스 공용이 되는 viaCache 모듈을 통해서 DB 통신을 최소화 하면 좋겠다.

3-2. 클라들 -> 서버 부하는, 서버는 특정 요청별 response 데이터 자체를 캐시해서 response 데이터 자체를 바로 응답하게 하면 속도를 올릴 수 있겠다. 그런데 한 서버가 동시에 처리할 수 있는 요청 자체는 15 req/sec 정도 한계가 생길 수 있다. 그래서 이걸 해결하기 위해 load balancer 를 통해 이를 다시 분할처리할 수도 있겠다.

4. 그런데 간혹 DB에서 값이 바뀔 가능성이 있다. 그래서 그날 전체 데이터의 hash 값이나 revision, changedTimestamp 같은걸 같이 저장해놔서, 클라이언트가 체크해서 다시 리로드할 수 있도록 하면 좋겠다.

5. 배포도 신경써야하는데, 그럼 꺼졌다 켜질 때 캐시 stempede 문제가 발생할 수 있기 때문에, 서버가 켜지고 요청을 받기전에 cache warm-up 로직도 넣으면 좋겠다.


6. 그런데 이렇게 하면 본질적인 latency를 줄이는건 한계가 있다. 최초의 첫번째 데이터가 캐시될 때까지 시간이 걸리는데, 그 반응성에 문제가 될 수 있다.

이것 자체도 더 개선하고 싶다면 클라이언트의 도움을 받아서, finalize 되기 전에도 해당 시점의 실시간 데이터들을 보내다가, 장이 닫혔을 때 변경된 데이터만 받으면, 장에서 모든 정보가 죄다 활발히 거래되는건 아니기 때문에 유저는 좀 더 빠르게 정보를 볼 수 있다.

7. backend DB는 뭘 쓸꺼냐, 시간, 종목, 변경된 데이터만 읽기 같은 복잡해질 수 있는 쿼리를 할 수 있는 SQL DB를 쓰면 좋겠다. schema가 있는게 데이터 스키마 관리에서도 좋기도 하고.

8. 종점 데이터가 주어진다는게, 내가 계산해야 하는건가? 아니면 실시간 데이터를 입력으로 받고, 내가 만들어 내야 하는건가? 후자라면 목적에 따라 in-memory nosql DB를 캐시 용도로 활용할 수 있겠다.

9. 통신 프로토콜은 JSON을 쓸 수 있겠는데, 파싱과 데이터가 커지는 단점이 있다. (키 반복) 이 경우는 숫자데이터들을 많이 보내기 때문에 binary protocol을 쓰면 좀 더 용량과 처리 시간을 많이 줄일 수 있다.
처리 시간 자체는 응답 전체를 캐시하면 많이 줄일 수 있으니 상관은 없지만, 용량을 줄이기 위한 대안으로 protobuf 정도를 생각해볼 수 있겠다.

10. 모니터링 해야하는거는 요청별 service 타임을 모니터닝하면서 서비스가 느려지는지 체크해야하겠고, 일정 시간 이상 되면 알람을 받도록 하겠다.

11. 종점 시점에 요청이 부스팅 되는건 거의 매일 반복되는 문제기 때문에 종점 시점 30분 점에 1시간 동안 서버 수를 자동으로 늘려놓는 식으로 부하에 선행 대응할 수 있겠다.

이거 클라이언트도 우리가 재공하는건지, API 서버 서비스만 재공하는건지 확인.

그냥 DB 자체를 재공하는 방법도 있다는걸 언급.

bulk dump를 원하는 유저를 위해 FTP나 파일 다운로드 기능을 재공하는 것도 언급.
